
% Default to the notebook output style

    


% Inherit from the specified cell style.




    
\documentclass[11pt]{article}

    
    
    \usepackage[T1]{fontenc}
    % Nicer default font (+ math font) than Computer Modern for most use cases
    \usepackage{mathpazo}

    % Basic figure setup, for now with no caption control since it's done
    % automatically by Pandoc (which extracts ![](path) syntax from Markdown).
    \usepackage{graphicx}
    % We will generate all images so they have a width \maxwidth. This means
    % that they will get their normal width if they fit onto the page, but
    % are scaled down if they would overflow the margins.
    \makeatletter
    \def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth
    \else\Gin@nat@width\fi}
    \makeatother
    \let\Oldincludegraphics\includegraphics
    % Set max figure width to be 80% of text width, for now hardcoded.
    \renewcommand{\includegraphics}[1]{\Oldincludegraphics[width=.8\maxwidth]{#1}}
    % Ensure that by default, figures have no caption (until we provide a
    % proper Figure object with a Caption API and a way to capture that
    % in the conversion process - todo).
    \usepackage{caption}
    \DeclareCaptionLabelFormat{nolabel}{}
    \captionsetup{labelformat=nolabel}

    \usepackage{adjustbox} % Used to constrain images to a maximum size 
    \usepackage{xcolor} % Allow colors to be defined
    \usepackage{enumerate} % Needed for markdown enumerations to work
    \usepackage{geometry} % Used to adjust the document margins
    \usepackage{amsmath} % Equations
    \usepackage{amssymb} % Equations
    \usepackage{textcomp} % defines textquotesingle
    % Hack from http://tex.stackexchange.com/a/47451/13684:
    \AtBeginDocument{%
        \def\PYZsq{\textquotesingle}% Upright quotes in Pygmentized code
    }
    \usepackage{upquote} % Upright quotes for verbatim code
    \usepackage{eurosym} % defines \euro
    \usepackage[mathletters]{ucs} % Extended unicode (utf-8) support
    \usepackage[utf8x]{inputenc} % Allow utf-8 characters in the tex document
    \usepackage{fancyvrb} % verbatim replacement that allows latex
    \usepackage{grffile} % extends the file name processing of package graphics 
                         % to support a larger range 
    % The hyperref package gives us a pdf with properly built
    % internal navigation ('pdf bookmarks' for the table of contents,
    % internal cross-reference links, web links for URLs, etc.)
    \usepackage{hyperref}
    \usepackage{longtable} % longtable support required by pandoc >1.10
    \usepackage{booktabs}  % table support for pandoc > 1.12.2
    \usepackage[inline]{enumitem} % IRkernel/repr support (it uses the enumerate* environment)
    \usepackage[normalem]{ulem} % ulem is needed to support strikethroughs (\sout)
                                % normalem makes italics be italics, not underlines
    

    
    
    % Colors for the hyperref package
    \definecolor{urlcolor}{rgb}{0,.145,.698}
    \definecolor{linkcolor}{rgb}{.71,0.21,0.01}
    \definecolor{citecolor}{rgb}{.12,.54,.11}

    % ANSI colors
    \definecolor{ansi-black}{HTML}{3E424D}
    \definecolor{ansi-black-intense}{HTML}{282C36}
    \definecolor{ansi-red}{HTML}{E75C58}
    \definecolor{ansi-red-intense}{HTML}{B22B31}
    \definecolor{ansi-green}{HTML}{00A250}
    \definecolor{ansi-green-intense}{HTML}{007427}
    \definecolor{ansi-yellow}{HTML}{DDB62B}
    \definecolor{ansi-yellow-intense}{HTML}{B27D12}
    \definecolor{ansi-blue}{HTML}{208FFB}
    \definecolor{ansi-blue-intense}{HTML}{0065CA}
    \definecolor{ansi-magenta}{HTML}{D160C4}
    \definecolor{ansi-magenta-intense}{HTML}{A03196}
    \definecolor{ansi-cyan}{HTML}{60C6C8}
    \definecolor{ansi-cyan-intense}{HTML}{258F8F}
    \definecolor{ansi-white}{HTML}{C5C1B4}
    \definecolor{ansi-white-intense}{HTML}{A1A6B2}

    % commands and environments needed by pandoc snippets
    % extracted from the output of `pandoc -s`
    \providecommand{\tightlist}{%
      \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
    \DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
    % Add ',fontsize=\small' for more characters per line
    \newenvironment{Shaded}{}{}
    \newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
    \newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.56,0.13,0.00}{{#1}}}
    \newcommand{\DecValTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\FloatTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\CharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\StringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\CommentTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textit{{#1}}}}
    \newcommand{\OtherTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{{#1}}}
    \newcommand{\AlertTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
    \newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.02,0.16,0.49}{{#1}}}
    \newcommand{\RegionMarkerTok}[1]{{#1}}
    \newcommand{\ErrorTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
    \newcommand{\NormalTok}[1]{{#1}}
    
    % Additional commands for more recent versions of Pandoc
    \newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.53,0.00,0.00}{{#1}}}
    \newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.73,0.40,0.53}{{#1}}}
    \newcommand{\ImportTok}[1]{{#1}}
    \newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.73,0.13,0.13}{\textit{{#1}}}}
    \newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\VariableTok}[1]{\textcolor[rgb]{0.10,0.09,0.49}{{#1}}}
    \newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
    \newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.40,0.40,0.40}{{#1}}}
    \newcommand{\BuiltInTok}[1]{{#1}}
    \newcommand{\ExtensionTok}[1]{{#1}}
    \newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.74,0.48,0.00}{{#1}}}
    \newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.49,0.56,0.16}{{#1}}}
    \newcommand{\InformationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\WarningTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    
    
    % Define a nice break command that doesn't care if a line doesn't already
    % exist.
    \def\br{\hspace*{\fill} \\* }
    % Math Jax compatability definitions
    \def\gt{>}
    \def\lt{<}
    % Document parameters
    \title{Tubes1A\_13517086}
    
    
    

    % Pygments definitions
    
\makeatletter
\def\PY@reset{\let\PY@it=\relax \let\PY@bf=\relax%
    \let\PY@ul=\relax \let\PY@tc=\relax%
    \let\PY@bc=\relax \let\PY@ff=\relax}
\def\PY@tok#1{\csname PY@tok@#1\endcsname}
\def\PY@toks#1+{\ifx\relax#1\empty\else%
    \PY@tok{#1}\expandafter\PY@toks\fi}
\def\PY@do#1{\PY@bc{\PY@tc{\PY@ul{%
    \PY@it{\PY@bf{\PY@ff{#1}}}}}}}
\def\PY#1#2{\PY@reset\PY@toks#1+\relax+\PY@do{#2}}

\expandafter\def\csname PY@tok@w\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.73,0.73}{##1}}}
\expandafter\def\csname PY@tok@c\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.74,0.48,0.00}{##1}}}
\expandafter\def\csname PY@tok@k\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kt\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.69,0.00,0.25}{##1}}}
\expandafter\def\csname PY@tok@o\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@ow\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\expandafter\def\csname PY@tok@nb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@nf\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@nc\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@nn\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@ne\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.82,0.25,0.23}{##1}}}
\expandafter\def\csname PY@tok@nv\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@no\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.53,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@nl\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.63,0.63,0.00}{##1}}}
\expandafter\def\csname PY@tok@ni\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.60,0.60,0.60}{##1}}}
\expandafter\def\csname PY@tok@na\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.49,0.56,0.16}{##1}}}
\expandafter\def\csname PY@tok@nt\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@nd\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\expandafter\def\csname PY@tok@s\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sd\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@si\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.53}{##1}}}
\expandafter\def\csname PY@tok@se\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.13}{##1}}}
\expandafter\def\csname PY@tok@sr\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.53}{##1}}}
\expandafter\def\csname PY@tok@ss\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@sx\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@m\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@gh\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@gu\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.50,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@gd\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.63,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@gi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.63,0.00}{##1}}}
\expandafter\def\csname PY@tok@gr\endcsname{\def\PY@tc##1{\textcolor[rgb]{1.00,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@ge\endcsname{\let\PY@it=\textit}
\expandafter\def\csname PY@tok@gs\endcsname{\let\PY@bf=\textbf}
\expandafter\def\csname PY@tok@gp\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@go\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.53,0.53,0.53}{##1}}}
\expandafter\def\csname PY@tok@gt\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.27,0.87}{##1}}}
\expandafter\def\csname PY@tok@err\endcsname{\def\PY@bc##1{\setlength{\fboxsep}{0pt}\fcolorbox[rgb]{1.00,0.00,0.00}{1,1,1}{\strut ##1}}}
\expandafter\def\csname PY@tok@kc\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kd\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kn\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kr\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@bp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@fm\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@vc\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@vg\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@vi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@vm\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@sa\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sc\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@dl\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@s2\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sh\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@s1\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@mb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mf\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mh\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@il\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mo\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@ch\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cm\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cpf\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@c1\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cs\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}

\def\PYZbs{\char`\\}
\def\PYZus{\char`\_}
\def\PYZob{\char`\{}
\def\PYZcb{\char`\}}
\def\PYZca{\char`\^}
\def\PYZam{\char`\&}
\def\PYZlt{\char`\<}
\def\PYZgt{\char`\>}
\def\PYZsh{\char`\#}
\def\PYZpc{\char`\%}
\def\PYZdl{\char`\$}
\def\PYZhy{\char`\-}
\def\PYZsq{\char`\'}
\def\PYZdq{\char`\"}
\def\PYZti{\char`\~}
% for compatibility with earlier versions
\def\PYZat{@}
\def\PYZlb{[}
\def\PYZrb{]}
\makeatother


    % Exact colors from NB
    \definecolor{incolor}{rgb}{0.0, 0.0, 0.5}
    \definecolor{outcolor}{rgb}{0.545, 0.0, 0.0}



    
    % Prevent overflowing lines due to hard-to-break entities
    \sloppy 
    % Setup hyperref package
    \hypersetup{
      breaklinks=true,  % so long urls are correctly broken across lines
      colorlinks=true,
      urlcolor=urlcolor,
      linkcolor=linkcolor,
      citecolor=citecolor,
      }
    % Slightly bigger margins than the latex defaults
    
    \geometry{verbose,tmargin=1in,bmargin=1in,lmargin=1in,rmargin=1in}
    
    

    \begin{document}
    
    
    \maketitle
    
    

    
    \hypertarget{tubes-i-bagian-a-eksplorasi-library-decision-tree-learning-pada-jupyter-notebook}{%
\section{Tubes I Bagian A: Eksplorasi library Decision Tree Learning
pada Jupyter
Notebook}\label{tubes-i-bagian-a-eksplorasi-library-decision-tree-learning-pada-jupyter-notebook}}

Oleh: • Kevin Angelo 13517086 • Juro Sutantra 13517113 • Nurul Utami
Amaliah W. 13517134 • Tasya Lailinissa Diandraputri 13517141

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}13}]:} \PY{c+c1}{\PYZsh{} Libraries}
         \PY{k+kn}{from} \PY{n+nn}{sklearn} \PY{k}{import} \PY{n}{datasets}
         \PY{k+kn}{import} \PY{n+nn}{pandas} \PY{k}{as} \PY{n+nn}{pd}
         \PY{k+kn}{from} \PY{n+nn}{sklearn} \PY{k}{import} \PY{n}{tree}
         \PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{tree} \PY{k}{import} \PY{n}{export\PYZus{}text}
         \PY{k+kn}{from} \PY{n+nn}{sklearn} \PY{k}{import} \PY{n}{preprocessing}
         \PY{k+kn}{from} \PY{n+nn}{id3} \PY{k}{import} \PY{n}{Id3Estimator}
         \PY{k+kn}{from} \PY{n+nn}{warnings} \PY{k}{import} \PY{n}{simplefilter}
         \PY{n}{simplefilter}\PY{p}{(}\PY{n}{action}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ignore}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{category}\PY{o}{=}\PY{n+ne}{FutureWarning}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}14}]:} \PY{c+c1}{\PYZsh{} Read iris dataset}
         \PY{n}{data\PYZus{}iris} \PY{o}{=} \PY{n}{datasets}\PY{o}{.}\PY{n}{load\PYZus{}iris}\PY{p}{(}\PY{p}{)}
         \PY{n}{data\PYZus{}iris}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}14}]:} \{'data': array([[5.1, 3.5, 1.4, 0.2],
                 [4.9, 3. , 1.4, 0.2],
                 [4.7, 3.2, 1.3, 0.2],
                 [4.6, 3.1, 1.5, 0.2],
                 [5. , 3.6, 1.4, 0.2],
                 [5.4, 3.9, 1.7, 0.4],
                 [4.6, 3.4, 1.4, 0.3],
                 [5. , 3.4, 1.5, 0.2],
                 [4.4, 2.9, 1.4, 0.2],
                 [4.9, 3.1, 1.5, 0.1],
                 [5.4, 3.7, 1.5, 0.2],
                 [4.8, 3.4, 1.6, 0.2],
                 [4.8, 3. , 1.4, 0.1],
                 [4.3, 3. , 1.1, 0.1],
                 [5.8, 4. , 1.2, 0.2],
                 [5.7, 4.4, 1.5, 0.4],
                 [5.4, 3.9, 1.3, 0.4],
                 [5.1, 3.5, 1.4, 0.3],
                 [5.7, 3.8, 1.7, 0.3],
                 [5.1, 3.8, 1.5, 0.3],
                 [5.4, 3.4, 1.7, 0.2],
                 [5.1, 3.7, 1.5, 0.4],
                 [4.6, 3.6, 1. , 0.2],
                 [5.1, 3.3, 1.7, 0.5],
                 [4.8, 3.4, 1.9, 0.2],
                 [5. , 3. , 1.6, 0.2],
                 [5. , 3.4, 1.6, 0.4],
                 [5.2, 3.5, 1.5, 0.2],
                 [5.2, 3.4, 1.4, 0.2],
                 [4.7, 3.2, 1.6, 0.2],
                 [4.8, 3.1, 1.6, 0.2],
                 [5.4, 3.4, 1.5, 0.4],
                 [5.2, 4.1, 1.5, 0.1],
                 [5.5, 4.2, 1.4, 0.2],
                 [4.9, 3.1, 1.5, 0.2],
                 [5. , 3.2, 1.2, 0.2],
                 [5.5, 3.5, 1.3, 0.2],
                 [4.9, 3.6, 1.4, 0.1],
                 [4.4, 3. , 1.3, 0.2],
                 [5.1, 3.4, 1.5, 0.2],
                 [5. , 3.5, 1.3, 0.3],
                 [4.5, 2.3, 1.3, 0.3],
                 [4.4, 3.2, 1.3, 0.2],
                 [5. , 3.5, 1.6, 0.6],
                 [5.1, 3.8, 1.9, 0.4],
                 [4.8, 3. , 1.4, 0.3],
                 [5.1, 3.8, 1.6, 0.2],
                 [4.6, 3.2, 1.4, 0.2],
                 [5.3, 3.7, 1.5, 0.2],
                 [5. , 3.3, 1.4, 0.2],
                 [7. , 3.2, 4.7, 1.4],
                 [6.4, 3.2, 4.5, 1.5],
                 [6.9, 3.1, 4.9, 1.5],
                 [5.5, 2.3, 4. , 1.3],
                 [6.5, 2.8, 4.6, 1.5],
                 [5.7, 2.8, 4.5, 1.3],
                 [6.3, 3.3, 4.7, 1.6],
                 [4.9, 2.4, 3.3, 1. ],
                 [6.6, 2.9, 4.6, 1.3],
                 [5.2, 2.7, 3.9, 1.4],
                 [5. , 2. , 3.5, 1. ],
                 [5.9, 3. , 4.2, 1.5],
                 [6. , 2.2, 4. , 1. ],
                 [6.1, 2.9, 4.7, 1.4],
                 [5.6, 2.9, 3.6, 1.3],
                 [6.7, 3.1, 4.4, 1.4],
                 [5.6, 3. , 4.5, 1.5],
                 [5.8, 2.7, 4.1, 1. ],
                 [6.2, 2.2, 4.5, 1.5],
                 [5.6, 2.5, 3.9, 1.1],
                 [5.9, 3.2, 4.8, 1.8],
                 [6.1, 2.8, 4. , 1.3],
                 [6.3, 2.5, 4.9, 1.5],
                 [6.1, 2.8, 4.7, 1.2],
                 [6.4, 2.9, 4.3, 1.3],
                 [6.6, 3. , 4.4, 1.4],
                 [6.8, 2.8, 4.8, 1.4],
                 [6.7, 3. , 5. , 1.7],
                 [6. , 2.9, 4.5, 1.5],
                 [5.7, 2.6, 3.5, 1. ],
                 [5.5, 2.4, 3.8, 1.1],
                 [5.5, 2.4, 3.7, 1. ],
                 [5.8, 2.7, 3.9, 1.2],
                 [6. , 2.7, 5.1, 1.6],
                 [5.4, 3. , 4.5, 1.5],
                 [6. , 3.4, 4.5, 1.6],
                 [6.7, 3.1, 4.7, 1.5],
                 [6.3, 2.3, 4.4, 1.3],
                 [5.6, 3. , 4.1, 1.3],
                 [5.5, 2.5, 4. , 1.3],
                 [5.5, 2.6, 4.4, 1.2],
                 [6.1, 3. , 4.6, 1.4],
                 [5.8, 2.6, 4. , 1.2],
                 [5. , 2.3, 3.3, 1. ],
                 [5.6, 2.7, 4.2, 1.3],
                 [5.7, 3. , 4.2, 1.2],
                 [5.7, 2.9, 4.2, 1.3],
                 [6.2, 2.9, 4.3, 1.3],
                 [5.1, 2.5, 3. , 1.1],
                 [5.7, 2.8, 4.1, 1.3],
                 [6.3, 3.3, 6. , 2.5],
                 [5.8, 2.7, 5.1, 1.9],
                 [7.1, 3. , 5.9, 2.1],
                 [6.3, 2.9, 5.6, 1.8],
                 [6.5, 3. , 5.8, 2.2],
                 [7.6, 3. , 6.6, 2.1],
                 [4.9, 2.5, 4.5, 1.7],
                 [7.3, 2.9, 6.3, 1.8],
                 [6.7, 2.5, 5.8, 1.8],
                 [7.2, 3.6, 6.1, 2.5],
                 [6.5, 3.2, 5.1, 2. ],
                 [6.4, 2.7, 5.3, 1.9],
                 [6.8, 3. , 5.5, 2.1],
                 [5.7, 2.5, 5. , 2. ],
                 [5.8, 2.8, 5.1, 2.4],
                 [6.4, 3.2, 5.3, 2.3],
                 [6.5, 3. , 5.5, 1.8],
                 [7.7, 3.8, 6.7, 2.2],
                 [7.7, 2.6, 6.9, 2.3],
                 [6. , 2.2, 5. , 1.5],
                 [6.9, 3.2, 5.7, 2.3],
                 [5.6, 2.8, 4.9, 2. ],
                 [7.7, 2.8, 6.7, 2. ],
                 [6.3, 2.7, 4.9, 1.8],
                 [6.7, 3.3, 5.7, 2.1],
                 [7.2, 3.2, 6. , 1.8],
                 [6.2, 2.8, 4.8, 1.8],
                 [6.1, 3. , 4.9, 1.8],
                 [6.4, 2.8, 5.6, 2.1],
                 [7.2, 3. , 5.8, 1.6],
                 [7.4, 2.8, 6.1, 1.9],
                 [7.9, 3.8, 6.4, 2. ],
                 [6.4, 2.8, 5.6, 2.2],
                 [6.3, 2.8, 5.1, 1.5],
                 [6.1, 2.6, 5.6, 1.4],
                 [7.7, 3. , 6.1, 2.3],
                 [6.3, 3.4, 5.6, 2.4],
                 [6.4, 3.1, 5.5, 1.8],
                 [6. , 3. , 4.8, 1.8],
                 [6.9, 3.1, 5.4, 2.1],
                 [6.7, 3.1, 5.6, 2.4],
                 [6.9, 3.1, 5.1, 2.3],
                 [5.8, 2.7, 5.1, 1.9],
                 [6.8, 3.2, 5.9, 2.3],
                 [6.7, 3.3, 5.7, 2.5],
                 [6.7, 3. , 5.2, 2.3],
                 [6.3, 2.5, 5. , 1.9],
                 [6.5, 3. , 5.2, 2. ],
                 [6.2, 3.4, 5.4, 2.3],
                 [5.9, 3. , 5.1, 1.8]]),
          'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
                 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
                 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
                 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
                 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
                 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
                 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]),
          'target\_names': array(['setosa', 'versicolor', 'virginica'], dtype='<U10'),
          'DESCR': '.. \_iris\_dataset:\textbackslash{}n\textbackslash{}nIris plants dataset\textbackslash{}n--------------------\textbackslash{}n\textbackslash{}n**Data Set Characteristics:**\textbackslash{}n\textbackslash{}n    :Number of Instances: 150 (50 in each of three classes)\textbackslash{}n    :Number of Attributes: 4 numeric, predictive attributes and the class\textbackslash{}n    :Attribute Information:\textbackslash{}n        - sepal length in cm\textbackslash{}n        - sepal width in cm\textbackslash{}n        - petal length in cm\textbackslash{}n        - petal width in cm\textbackslash{}n        - class:\textbackslash{}n                - Iris-Setosa\textbackslash{}n                - Iris-Versicolour\textbackslash{}n                - Iris-Virginica\textbackslash{}n                \textbackslash{}n    :Summary Statistics:\textbackslash{}n\textbackslash{}n    ============== ==== ==== ======= ===== ====================\textbackslash{}n                    Min  Max   Mean    SD   Class Correlation\textbackslash{}n    ============== ==== ==== ======= ===== ====================\textbackslash{}n    sepal length:   4.3  7.9   5.84   0.83    0.7826\textbackslash{}n    sepal width:    2.0  4.4   3.05   0.43   -0.4194\textbackslash{}n    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\textbackslash{}n    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\textbackslash{}n    ============== ==== ==== ======= ===== ====================\textbackslash{}n\textbackslash{}n    :Missing Attribute Values: None\textbackslash{}n    :Class Distribution: 33.3\% for each of 3 classes.\textbackslash{}n    :Creator: R.A. Fisher\textbackslash{}n    :Donor: Michael Marshall (MARSHALL\%PLU@io.arc.nasa.gov)\textbackslash{}n    :Date: July, 1988\textbackslash{}n\textbackslash{}nThe famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\textbackslash{}nfrom Fisher\textbackslash{}'s paper. Note that it\textbackslash{}'s the same as in R, but not as in the UCI\textbackslash{}nMachine Learning Repository, which has two wrong data points.\textbackslash{}n\textbackslash{}nThis is perhaps the best known database to be found in the\textbackslash{}npattern recognition literature.  Fisher\textbackslash{}'s paper is a classic in the field and\textbackslash{}nis referenced frequently to this day.  (See Duda \& Hart, for example.)  The\textbackslash{}ndata set contains 3 classes of 50 instances each, where each class refers to a\textbackslash{}ntype of iris plant.  One class is linearly separable from the other 2; the\textbackslash{}nlatter are NOT linearly separable from each other.\textbackslash{}n\textbackslash{}n.. topic:: References\textbackslash{}n\textbackslash{}n   - Fisher, R.A. "The use of multiple measurements in taxonomic problems"\textbackslash{}n     Annual Eugenics, 7, Part II, 179-188 (1936); also in "Contributions to\textbackslash{}n     Mathematical Statistics" (John Wiley, NY, 1950).\textbackslash{}n   - Duda, R.O., \& Hart, P.E. (1973) Pattern Classification and Scene Analysis.\textbackslash{}n     (Q327.D83) John Wiley \& Sons.  ISBN 0-471-22361-1.  See page 218.\textbackslash{}n   - Dasarathy, B.V. (1980) "Nosing Around the Neighborhood: A New System\textbackslash{}n     Structure and Classification Rule for Recognition in Partially Exposed\textbackslash{}n     Environments".  IEEE Transactions on Pattern Analysis and Machine\textbackslash{}n     Intelligence, Vol. PAMI-2, No. 1, 67-71.\textbackslash{}n   - Gates, G.W. (1972) "The Reduced Nearest Neighbor Rule".  IEEE Transactions\textbackslash{}n     on Information Theory, May 1972, 431-433.\textbackslash{}n   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al"s AUTOCLASS II\textbackslash{}n     conceptual clustering system finds 3 classes in the data.\textbackslash{}n   - Many, many more {\ldots}',
          'feature\_names': ['sepal length (cm)',
           'sepal width (cm)',
           'petal length (cm)',
           'petal width (cm)'],
          'filename': '/Users/Tasya/anaconda3/lib/python3.6/site-packages/sklearn/datasets/data/iris.csv'\}
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}15}]:} \PY{c+c1}{\PYZsh{} Read play\PYZhy{}tennis dataset}
         \PY{n}{data\PYZus{}play\PYZus{}tennis} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{read\PYZus{}csv}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{play\PYZhy{}tennis.csv}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         \PY{n}{data\PYZus{}play\PYZus{}tennis} \PY{o}{=} \PY{n}{data\PYZus{}play\PYZus{}tennis}\PY{o}{.}\PY{n}{values}\PY{o}{.}\PY{n}{tolist}\PY{p}{(}\PY{p}{)}
         \PY{n}{data\PYZus{}play\PYZus{}tennis}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}15}]:} [['D1', 'Sunny', 'Hot', 'High', 'Weak', 'No'],
          ['D2', 'Sunny', 'Hot', 'High', 'Strong', 'No'],
          ['D3', 'Overcast', 'Hot', 'High', 'Weak', 'Yes'],
          ['D4', 'Rain', 'Mild', 'High', 'Weak', 'Yes'],
          ['D5', 'Rain', 'Cool', 'Normal', 'Weak', 'Yes'],
          ['D6', 'Rain', 'Cool', 'Normal', 'Strong', 'No'],
          ['D7', 'Overcast', 'Cool', 'Normal', 'Strong', 'Yes'],
          ['D8', 'Sunny', 'Mild', 'High', 'Weak', 'No'],
          ['D9', 'Sunny', 'Cool', 'Normal', 'Weak', 'Yes'],
          ['D10', 'Rain', 'Mild', 'Normal', 'Weak', 'Yes'],
          ['D11', 'Sunny', 'Mild', 'Normal', 'Strong', 'Yes'],
          ['D12', 'Overcast', 'Mild', 'High', 'Strong', 'Yes'],
          ['D13', 'Overcast', 'Hot', 'Normal', 'Weak', 'Yes'],
          ['D14', 'Rain', 'Mild', 'High', 'Strong', 'No']]
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}16}]:} \PY{c+c1}{\PYZsh{} play\PYZhy{}tennis target}
         \PY{n}{data\PYZus{}play\PYZus{}tennis\PYZus{}target} \PY{o}{=} \PY{p}{[}\PY{p}{]}
         \PY{k}{for} \PY{n}{x} \PY{o+ow}{in} \PY{n}{data\PYZus{}play\PYZus{}tennis}\PY{p}{:}
             \PY{n}{data\PYZus{}play\PYZus{}tennis\PYZus{}target}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{x}\PY{p}{[}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{:}\PY{p}{]}\PY{p}{)}
         \PY{n}{data\PYZus{}play\PYZus{}tennis\PYZus{}target}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}16}]:} [['No'],
          ['No'],
          ['Yes'],
          ['Yes'],
          ['Yes'],
          ['No'],
          ['Yes'],
          ['No'],
          ['Yes'],
          ['Yes'],
          ['Yes'],
          ['Yes'],
          ['Yes'],
          ['No']]
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}17}]:} \PY{c+c1}{\PYZsh{} play\PYZhy{}tennis data}
         \PY{n}{data\PYZus{}play\PYZus{}tennis\PYZus{}data} \PY{o}{=} \PY{p}{[}\PY{p}{]}
         \PY{k}{for} \PY{n}{x} \PY{o+ow}{in} \PY{n}{data\PYZus{}play\PYZus{}tennis}\PY{p}{:}
             \PY{n}{data\PYZus{}play\PYZus{}tennis\PYZus{}data}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{x}\PY{p}{[}\PY{p}{:}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{:}\PY{p}{]}\PY{p}{)}
         \PY{n}{data\PYZus{}play\PYZus{}tennis\PYZus{}data}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}17}]:} [['Sunny', 'Hot', 'High', 'Weak'],
          ['Sunny', 'Hot', 'High', 'Strong'],
          ['Overcast', 'Hot', 'High', 'Weak'],
          ['Rain', 'Mild', 'High', 'Weak'],
          ['Rain', 'Cool', 'Normal', 'Weak'],
          ['Rain', 'Cool', 'Normal', 'Strong'],
          ['Overcast', 'Cool', 'Normal', 'Strong'],
          ['Sunny', 'Mild', 'High', 'Weak'],
          ['Sunny', 'Cool', 'Normal', 'Weak'],
          ['Rain', 'Mild', 'Normal', 'Weak'],
          ['Sunny', 'Mild', 'Normal', 'Strong'],
          ['Overcast', 'Mild', 'High', 'Strong'],
          ['Overcast', 'Hot', 'Normal', 'Weak'],
          ['Rain', 'Mild', 'High', 'Strong']]
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}18}]:} \PY{c+c1}{\PYZsh{} DecisionTreeClassifier iris}
         \PY{n}{iris\PYZus{}tree} \PY{o}{=} \PY{n}{tree}\PY{o}{.}\PY{n}{DecisionTreeClassifier}\PY{p}{(}\PY{p}{)}
         \PY{n}{iris\PYZus{}tree} \PY{o}{=} \PY{n}{iris\PYZus{}tree}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{data\PYZus{}iris}\PY{o}{.}\PY{n}{data}\PY{p}{,} \PY{n}{data\PYZus{}iris}\PY{o}{.}\PY{n}{target}\PY{p}{)}
         \PY{n}{iris\PYZus{}tree\PYZus{}text} \PY{o}{=} \PY{n}{export\PYZus{}text}\PY{p}{(}\PY{n}{iris\PYZus{}tree}\PY{p}{,} \PY{n}{feature\PYZus{}names}\PY{o}{=}\PY{n}{data\PYZus{}iris}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{feature\PYZus{}names}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{n}{iris\PYZus{}tree\PYZus{}text}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
|--- petal width (cm) <= 0.80
|   |--- class: 0
|--- petal width (cm) >  0.80
|   |--- petal width (cm) <= 1.75
|   |   |--- petal length (cm) <= 4.95
|   |   |   |--- petal width (cm) <= 1.65
|   |   |   |   |--- class: 1
|   |   |   |--- petal width (cm) >  1.65
|   |   |   |   |--- class: 2
|   |   |--- petal length (cm) >  4.95
|   |   |   |--- petal width (cm) <= 1.55
|   |   |   |   |--- class: 2
|   |   |   |--- petal width (cm) >  1.55
|   |   |   |   |--- sepal length (cm) <= 6.95
|   |   |   |   |   |--- class: 1
|   |   |   |   |--- sepal length (cm) >  6.95
|   |   |   |   |   |--- class: 2
|   |--- petal width (cm) >  1.75
|   |   |--- petal length (cm) <= 4.85
|   |   |   |--- sepal width (cm) <= 3.10
|   |   |   |   |--- class: 2
|   |   |   |--- sepal width (cm) >  3.10
|   |   |   |   |--- class: 1
|   |   |--- petal length (cm) >  4.85
|   |   |   |--- class: 2


    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}26}]:} \PY{c+c1}{\PYZsh{} Preprocess play\PYZhy{}tennis target}
         \PY{n}{tennis} \PY{o}{=} \PY{n}{preprocessing}\PY{o}{.}\PY{n}{LabelEncoder}\PY{p}{(}\PY{p}{)}
         \PY{n}{tennis}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{data\PYZus{}play\PYZus{}tennis\PYZus{}target}\PY{p}{)}
         \PY{n+nb}{list}\PY{p}{(}\PY{n}{tennis}\PY{o}{.}\PY{n}{classes\PYZus{}}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
/Users/Tasya/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/\_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n\_samples, ), for example using ravel().
  y = column\_or\_1d(y, warn=True)

    \end{Verbatim}

\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}26}]:} ['No', 'Yes']
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}27}]:} \PY{c+c1}{\PYZsh{} Encode play\PYZhy{}tennis target}
         \PY{n}{data\PYZus{}play\PYZus{}tennis\PYZus{}target\PYZus{}labeled} \PY{o}{=} \PY{n}{tennis}\PY{o}{.}\PY{n}{transform}\PY{p}{(}\PY{n}{data\PYZus{}play\PYZus{}tennis\PYZus{}target}\PY{p}{)}
         \PY{n}{data\PYZus{}play\PYZus{}tennis\PYZus{}target\PYZus{}labeled}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
/Users/Tasya/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/\_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n\_samples, ), for example using ravel().
  y = column\_or\_1d(y, warn=True)

    \end{Verbatim}

\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}27}]:} array([0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0])
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}21}]:} \PY{c+c1}{\PYZsh{} Preprocess play\PYZhy{}tennis data}
         \PY{n}{data\PYZus{}play\PYZus{}tennis\PYZus{}data\PYZus{}transpose} \PY{o}{=} \PY{n+nb}{map}\PY{p}{(}\PY{n+nb}{list}\PY{p}{,} \PY{n+nb}{zip}\PY{p}{(}\PY{o}{*}\PY{n}{data\PYZus{}play\PYZus{}tennis\PYZus{}data}\PY{p}{)}\PY{p}{)}
         \PY{n}{data\PYZus{}play\PYZus{}tennis\PYZus{}data\PYZus{}labeled} \PY{o}{=} \PY{p}{[}\PY{p}{]}
         \PY{k}{for} \PY{n}{x} \PY{o+ow}{in} \PY{n}{data\PYZus{}play\PYZus{}tennis\PYZus{}data\PYZus{}transpose}\PY{p}{:}
             \PY{n}{tennis}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{x}\PY{p}{)}
             \PY{n}{data\PYZus{}play\PYZus{}tennis\PYZus{}data\PYZus{}labeled}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{tennis}\PY{o}{.}\PY{n}{transform}\PY{p}{(}\PY{n}{x}\PY{p}{)}\PY{p}{)} 
         \PY{n}{data\PYZus{}play\PYZus{}tennis\PYZus{}data\PYZus{}labeled} \PY{o}{=} \PY{n+nb}{list}\PY{p}{(}\PY{n+nb}{map}\PY{p}{(}\PY{n+nb}{list}\PY{p}{,} \PY{n+nb}{zip}\PY{p}{(}\PY{o}{*}\PY{n}{data\PYZus{}play\PYZus{}tennis\PYZus{}data\PYZus{}labeled}\PY{p}{)}\PY{p}{)}\PY{p}{)}
         \PY{n}{data\PYZus{}play\PYZus{}tennis\PYZus{}data\PYZus{}labeled}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}21}]:} [[2, 1, 0, 1],
          [2, 1, 0, 0],
          [0, 1, 0, 1],
          [1, 2, 0, 1],
          [1, 0, 1, 1],
          [1, 0, 1, 0],
          [0, 0, 1, 0],
          [2, 2, 0, 1],
          [2, 0, 1, 1],
          [1, 2, 1, 1],
          [2, 2, 1, 0],
          [0, 2, 0, 0],
          [0, 1, 1, 1],
          [1, 2, 0, 0]]
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}22}]:} \PY{c+c1}{\PYZsh{} DecisionTreeClassifier play\PYZhy{}tennis}
         \PY{n}{play\PYZus{}tennis\PYZus{}tree} \PY{o}{=} \PY{n}{tree}\PY{o}{.}\PY{n}{DecisionTreeClassifier}\PY{p}{(}\PY{p}{)}
         \PY{n}{play\PYZus{}tennis\PYZus{}tree} \PY{o}{=} \PY{n}{play\PYZus{}tennis\PYZus{}tree}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{data\PYZus{}play\PYZus{}tennis\PYZus{}data\PYZus{}labeled}\PY{p}{,} \PY{n}{data\PYZus{}play\PYZus{}tennis\PYZus{}target\PYZus{}labeled}\PY{p}{)}
         \PY{n}{play\PYZus{}tennis\PYZus{}tree\PYZus{}text} \PY{o}{=} \PY{n}{export\PYZus{}text}\PY{p}{(}\PY{n}{play\PYZus{}tennis\PYZus{}tree}\PY{p}{,} \PY{n}{feature\PYZus{}names} \PY{o}{=} \PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{outlook}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{temp}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{humidity}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{wind}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{n}{play\PYZus{}tennis\PYZus{}tree\PYZus{}text}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
|--- outlook <= 0.50
|   |--- class: 1
|--- outlook >  0.50
|   |--- humidity <= 0.50
|   |   |--- outlook <= 1.50
|   |   |   |--- wind <= 0.50
|   |   |   |   |--- class: 0
|   |   |   |--- wind >  0.50
|   |   |   |   |--- class: 1
|   |   |--- outlook >  1.50
|   |   |   |--- class: 0
|   |--- humidity >  0.50
|   |   |--- wind <= 0.50
|   |   |   |--- outlook <= 1.50
|   |   |   |   |--- class: 0
|   |   |   |--- outlook >  1.50
|   |   |   |   |--- class: 1
|   |   |--- wind >  0.50
|   |   |   |--- class: 1


    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}23}]:} \PY{k+kn}{from} \PY{n+nn}{id3} \PY{k}{import} \PY{n}{export\PYZus{}text}
         \PY{c+c1}{\PYZsh{} Id3Estimator iris}
         \PY{n}{estimator\PYZus{}iris} \PY{o}{=} \PY{n}{Id3Estimator}\PY{p}{(}\PY{p}{)}
         \PY{n}{estimator\PYZus{}iris} \PY{o}{=} \PY{n}{estimator\PYZus{}iris}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{data\PYZus{}iris}\PY{o}{.}\PY{n}{data}\PY{p}{,} \PY{n}{data\PYZus{}iris}\PY{o}{.}\PY{n}{target}\PY{p}{)}
         \PY{n}{estimator\PYZus{}iris\PYZus{}text} \PY{o}{=} \PY{n}{export\PYZus{}text}\PY{p}{(}\PY{n}{estimator\PYZus{}iris}\PY{o}{.}\PY{n}{tree\PYZus{}}\PY{p}{,} \PY{n}{feature\PYZus{}names}\PY{o}{=}\PY{n}{data\PYZus{}iris}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{feature\PYZus{}names}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{n}{estimator\PYZus{}iris\PYZus{}text}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]

petal length (cm) <=2.45: 0 (50) 
petal length (cm) >2.45
|   petal width (cm) <=1.75
|   |   sepal length (cm) <=7.10
|   |   |   sepal width (cm) <=2.85: 1 (27/4) 
|   |   |   sepal width (cm) >2.85: 1 (22) 
|   |   sepal length (cm) >7.10: 2 (1) 
|   petal width (cm) >1.75
|   |   sepal length (cm) <=5.95
|   |   |   sepal width (cm) <=3.10: 2 (6) 
|   |   |   sepal width (cm) >3.10: 1 (1) 
|   |   sepal length (cm) >5.95: 2 (39) 


    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}25}]:} \PY{c+c1}{\PYZsh{} Id3Estimator play\PYZhy{}tennis}
         \PY{n}{estimator\PYZus{}play\PYZus{}tennis} \PY{o}{=} \PY{n}{Id3Estimator}\PY{p}{(}\PY{p}{)}
         \PY{n}{estimator\PYZus{}play\PYZus{}tennis} \PY{o}{=} \PY{n}{estimator\PYZus{}play\PYZus{}tennis}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{data\PYZus{}play\PYZus{}tennis\PYZus{}data\PYZus{}labeled}\PY{p}{,} \PY{n}{data\PYZus{}play\PYZus{}tennis\PYZus{}target\PYZus{}labeled}\PY{p}{)}
         \PY{n}{estimator\PYZus{}play\PYZus{}tennis\PYZus{}text} \PY{o}{=} \PY{n}{export\PYZus{}text}\PY{p}{(}\PY{n}{estimator\PYZus{}play\PYZus{}tennis}\PY{o}{.}\PY{n}{tree\PYZus{}}\PY{p}{,} \PY{n}{feature\PYZus{}names} \PY{o}{=} \PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{outlook}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{temp}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{humidity}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{wind}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{n}{estimator\PYZus{}play\PYZus{}tennis\PYZus{}text}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]

outlook <=0.50: 1 (4) 
outlook >0.50
|   humidity <=0.50
|   |   temp <=1.50: 0 (2) 
|   |   temp >1.50
|   |   |   wind <=0.50: 0 (1) 
|   |   |   wind >0.50: 0 (1/1) 
|   humidity >0.50
|   |   wind <=0.50
|   |   |   temp <=1.00: 0 (1) 
|   |   |   temp >1.00: 1 (1) 
|   |   wind >0.50: 1 (3) 


    \end{Verbatim}

    \hypertarget{analisis-algoritma}{%
\section{Analisis Algoritma}\label{analisis-algoritma}}

    \hypertarget{a.-penentuan-atribut-terbaik}{%
\subsection{a. Penentuan atribut
terbaik}\label{a.-penentuan-atribut-terbaik}}

    Pada library DecisionTreeClassifier, atribut terbaik ditentukan oleh
salah satu algoritma \emph{decision tree} yaitu CART (Classification and
Regression Tree) yang memanfaatkan \emph{Gini Index}. Untuk atribut yang
bernilai diskrit, \emph{splitting} atribut akan dipilih berdasarkan
subset dengan \emph{Gini Index terkecil} (minimum).

Algoritma ID3 pada buku menentukan atribut terbaik dengan konsep
\emph{entropy} untuk menilai seberapa informatif suatu simpul. Kemudian,
pemilihan atribut dilakukan berdasarkan nilai \emph{Information Gain}
terbesar.

Modul ID3Estimator sama dengan algoritma pada buku karena modul ini
dibangun menggunakan algoritma ID3.

Persamaan: Melakukan pemilihan atribut berdasarkan pilihan terbaik
sesuai dengan \emph{attribute selection measures} masing-masing

    \hypertarget{b.-penanganan-label-dari-cabang-setiap-nilai-atribut}{%
\subsection{b. Penanganan label dari cabang setiap nilai
atribut}\label{b.-penanganan-label-dari-cabang-setiap-nilai-atribut}}

    Algoritma ID3 pada buku menetukan label berdasarkan nilai data dari
\emph{example}. Jika semua \emph{example} bernilai positif akan dibentuk
\emph{single-node tree} dari \emph{root} dengan label ``+'' (positif).
Begitu juga jika semua \emph{example} bernilai negatif akan dibentuk
\emph{single-node tree} dari \emph{root} dengan label ``-'' (negatif).
Begitu seterusnya hingga ditemukan \emph{example} kosong atau atribut
sudah kosong.

Pada library DecisionTreeClassifier yang menggunakan algoritma CART,
pemberian label dilakukan mengikuti aturan jumlah terbanyak, karena
proses ini akan memilih label dengan peluang terbesar. Begitu juga untuk
\emph{example} dengan data yang homogen, proses \emph{splitting} akan
dihentikan dan diberi label berdasarkan nilai terbanyak yaitu nilai satu
satunya yang ada pada \emph{example} (karena homogen).

Pada modul ID3Estimator penanganan label sama seperti algoritma ID3 pada
buku.

Persamaan: Penanganan label pada data yang homogen, menghentikan proses
\emph{splitting} dan membentuk \emph{single-node} dengan nilai yang
sesuai dengan nilai pada data homogen tersebut.

    \hypertarget{c.-penentuan-label-jika-examples-kosong-di-cabang-tersebut}{%
\subsection{\texorpdfstring{c.~Penentuan label jika \emph{examples}
kosong di cabang
tersebut}{c.~Penentuan label jika examples kosong di cabang tersebut}}\label{c.-penentuan-label-jika-examples-kosong-di-cabang-tersebut}}

    Pada library DecisionTreeClassifier menentukan label jika \emph{example}
kosong sama dengan penanganan label seperti biasanya, seperti yang telah
dijabarkan sebelumnya pada penanganan label dari cabang setiap nilai
atribut. DecisionTreeClassifier akan melakukan proses pelabelan yang
sama hingga simpul terakhir.

Algoritma ID3 pada buku memberi label jika ditemukan example kosong
dengan membentuk simpul daun pada cabang tersebut dengan label nilai
modus (paling sering muncul) dari target atribut pada \emph{example}.

Pada modul ID3Estimator penanganan label sama seperti algoritma ID3 pada
buku yaitu dengan melakukan pelabelan sesuai data terbanyak dari atribut
pada \emph{example}.

Persamaan: Penanganan label pada \emph{example} kosong, pada dasarnya
ketiganya melakukan proses yang sama yaitu memeberi label sesuai dengan
data terbanyak pada atribut.

    \hypertarget{d.-penanganan-atribut-kontinu}{%
\subsection{d.~Penanganan atribut
kontinu}\label{d.-penanganan-atribut-kontinu}}

    Library DecisionTreeClassifier mempartisi nilai-nilai pada atribut
kontinu tersebut ke interval-interval untuk menentukan kelas yang cocok
untuk tiap instans, sehingga tiap simpul pada \emph{decision tree} akan
menghitung nilai dari atribut suatu instans dan mencocokkan nilai
tersebut ke interval yang sudah ditentukan. Misalnya, untuk dataset
jenis kelamin, dan terdapat atribut tinggi badan, maka dapat
diaproksimasi interval tinggi \textless{} 160 cm akan menjadi kelas
`wanita', dan tinggi \textgreater= 160 cm masuk ke kelas `pria'.

Id3Estimator men'diskrit'kan nilai-nilai kontinu untuk memudahkan
klasifikasi. Untuk tiap nilai pada tiap atribut kontinu, akan dihitung
suatu poin yang dapat membagi (\emph{split}) rentang nilai atribut ke
grup yang paling homogen pada tiap level pembagian, dengan cara
menghitung \emph{information gain} dari tiap kemungkinan
\emph{splitting} dan memilih \emph{splitting} dengan \emph{information
gain} terbesar.

Untuk algoritma pada buku, mirip dengan Id3Estimator, juga ditentukan
suatu poin \emph{splitting} yang memiliki \emph{information gain}
terbesar, sehingga dapat mengkategorikan nilai-nilai kontinu ke grup
yang sehomogen mungkin.

Persamaan: Nilai-nilai atribut dibagi dengan satu atau beberapa interval
untuk proses kategorisasi.

    \hypertarget{e.-penanganan-atribut-dengan-missing-values}{%
\subsection{\texorpdfstring{e. Penanganan atribut dengan \emph{missing
values}}{e. Penanganan atribut dengan missing values}}\label{e.-penanganan-atribut-dengan-missing-values}}

    Pada DecisionTreeClassifier, \emph{missing value} diabaikan hanya saat
evaluasi (penentuan titik \emph{splitting}), sedangkan saat klasifikasi,
instans dengan \emph{missing value} tetap dikategorikan. Instans yang
berisi \emph{missing values} biasanya dikategorikan ke dalam target
dengan jumlah instans terbanyak yang sudah dikategorikan (modus),
ataupun dikategorikan ke dalam kelas lain dengan perhitungan yang sudah
disesuaikan.

Id3Estimator secara \emph{default} mengabaikan instans dengan
\emph{missing values}, dan dapat berakibat pada tidak optimalnya hasil
yang didapatkan seandainya instans yang diabaikan memegang peran penting
(memiliki bobot yang besar) pada pembentukan pohon.

Algoritma pada buku melabelkan instans dengan \emph{missing values}
dengan jumlah nilai label terbanyak di data latih (modus).

Persamaan: Tidak ada kesamaan ketiga pendekatan dalam penanganan
\emph{missing values}. Namun, untuk menghindari pengurangan keakurasian
hasil karena \emph{missing values}, biasanya dilakukan imputasi data
pada dataset, yaitu menghitung atau memperkirakan nilai yang hilang
tersebut. Nilai yang biasanya dipakai adalah median (nilai tengah), mean
(rata-rata) ataupun modus (nilai yang paling sering muncul).

    \hypertarget{f.-pruning-dan-parameter-confidence}{%
\subsection{\texorpdfstring{f.~\emph{Pruning} dan parameter
\emph{confidence}}{f.~Pruning dan parameter confidence}}\label{f.-pruning-dan-parameter-confidence}}

    \emph{Pruning} pada DecisionTreeClassifier dilakukan dengan mengubah
nilai parameter \texttt{min\_samples\_leaf} dan \texttt{max\_depth} yang
mengatur jumlah sampel minimum yang diperlukan untuk melakukan
\emph{splitting} dan kedalaman dari pohon. Terdapat pula opsi lain untuk
mengatur ukuran dari pohon yang dihasilkan, yaitu parameter
\texttt{cpp\_alpha}. Semakin besar nilai \texttt{cpp\_alpha}, semakin
banyak simpul yang akan di-\emph{prune}. Penentuan nilai
\texttt{cpp\_alpha} yang optimal sangat penting, karena simpul yang
di-\emph{prune} diharapkan tidak terlalu banyak sehingga nilai parameter
\emph{confidence} berkurang, tetapi juga tidak terlalu sedikit agar
tidak menyebabkan \emph{overfitting}. Telah disediakan fungsi
\texttt{DecisionTreeClassifier.cost\_complexity\_pruning\_path} dari
\texttt{scikit-learn} yang mengembalikan nilai \texttt{cpp\_alpha} yang
efektif, di mana prioritas \emph{pruning} yang diterapkan adalah
terhadap simpul dengan \emph{link} terlemah.

Secara \emph{default}, Id3Estimator akan terus membangun pohon sampai
didapatkan tingkat parameter \emph{confidence} setinggi mungkin dan
\emph{error} pada data latih mencapai 0\%, sehingga \emph{pruning} harus
dilakukan untuk menghindari \emph{overfitting}. Proses \emph{pruning}
yang dilakukan disebut juga sebagai \emph{Reduced-Error Pruning},
dimulai dengan menjadikan tiap simpul bukan daun menjadi daun, lalu
simpul tersebut di-\emph{assign} dengan nilai yang paling umum dari
anak-anak simpul tersebut. Bila \emph{error} yang dihasilkan pohon baru
ini pada data validasi tidak lebih buruk dari \emph{error} yang
dihasilkan pohon original, maka pohon baru ini akan menggantikan pohon
yang lama. Proses ini dilakukan terus sampai tingkat \emph{error} yang
dihasilkan meningkat drastis, yang menyebabkan pengurangan tingkat
akurasi pohon.

Algoritma pada buku mirip dengan Id3Estimator, yaitu mengaplikasikan
\emph{pruning} dengan membuang simpul yang tidak `berbahaya', yaitu
simpul yang dapat menurunkan tingkat akurasi dan parameter
\emph{confidence} pohon secara signifikan.

Persamaan: Ketiga pendekatan mengatur ukuran pohon yang dihasilkan
dengan membuang simpul yang dianggap tidak mengganggu dan mengubah
tingkat akurasi pohon, sehingga pohon yang dihasilkan tidak terlalu
spesifik untuk data latih saja.


    % Add a bibliography block to the postdoc
    
    
    
    \end{document}
